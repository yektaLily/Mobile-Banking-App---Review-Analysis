{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05981aa-7546-4d52-8105-4af96ee798b5",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS \n",
    "\n",
    "In this document, we will be classifying for Google and IOS app store reviews using sentiment analysis into positive, neutral and negative reviews. The result would be separating the original reviews data into 3 separate datasets, and conducting topic modeling on each. The steps to achieve this are as follows: \n",
    "\n",
    "#### Manual data labeling \n",
    "1. Calculate the mean score (rating) across dataset  \n",
    "2. Calculate the standard deviation of the scores/rating across dataset  \n",
    "3. Calculate and store $\\mu + \\sigma$ in variables called as “upper_accepted” and “lower_accepted”  \n",
    "4. Manually label data (add column \"man_label\" to data), as follows:  \n",
    "\tA. If score/rating > upper_accepted  $\\rightarrow$  man_label = positive  \n",
    "\tB. If score < lower_accepted $\\rightarrow$ man_label = negative  \n",
    "\tC. If lower_accepted $\\leq$  score $\\leq$ upper_accepted  $\\rightarrow$ man_label = neutral  \n",
    "\n",
    "\n",
    "#### Sentiment Analysis Labeling \n",
    "0. Do cross-validation (train, test, validation) \n",
    "1. Use various sentiment analysis tools to label data \n",
    "2. Use other classification and clustering algorithms to label data \n",
    "3. Find the algorithm/technique with the most accurate results (compared with our manual labeling)\n",
    "4. Do sanity checks of reading the reviews by authors to make sure the labels created make sense  \n",
    "5. Save 3 separate datasets, `positive_reviews`, `negative_reviews` and `neutral_reviews` \n",
    "\n",
    "#### TOPIC MODELING for each \n",
    "Next, in a separate file, each of the three datasets above (separately for iOS and Google, of course) will go through topic modeling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ba0242-9f5a-4f03-a411-baa9225dcfe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install itertools\n",
    "!pip install spacy\n",
    "!pip install langdetect\n",
    "!pip install pprint\n",
    "!pip install pyLDAvis\n",
    "!pip install vaderSentiment\n",
    "!pip install textblob\n",
    "!pip install keras\n",
    "!pip install transformers\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d06249a-136d-448b-a64a-aeb710261645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.corpora import MmCorpus\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "import spacy\n",
    "from langdetect import detect, DetectorFactory\n",
    "from gensim.models import CoherenceModel\n",
    "from string import punctuation\n",
    "from pprint import pprint\n",
    "import gensim.models\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis.gensim\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "from textblob import TextBlob\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "from textblob import Word\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0995b637-c49a-4338-b64c-835219234140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /home/yekta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/names.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/yekta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /home/yekta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/state_union.zip.\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/yekta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/yekta/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yekta/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/yekta/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/yekta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791cbffb-0cbb-4dbc-91f0-a62642bd2243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e10862-105b-47f4-b537-6c892fd906ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------- START OF CHATGPT CODE\n",
    "# PROMPT was: finish this function: def save_file(name, extension, content):\n",
    "def save_file(name, extension, content):\n",
    "    \"\"\"\n",
    "    Save a file with the specified name, extension, and content.\n",
    "\n",
    "    Args:\n",
    "    name (str): The name of the file (without extension).\n",
    "    extension (str): The file extension (e.g., 'txt', 'csv').\n",
    "    content (str): The content to be saved in the file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Combine name and extension to form the full file name\n",
    "    filename = f\"{name}.{extension}\"\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"The file {filename} already exists. Overwriting...\")\n",
    "    \n",
    "    # Open the file and write the content\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(content)\n",
    "        print(f\"File {filename} saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while saving file: {e}\")\n",
    "# ---------------------- END OF CHATGPT CODE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "effedbc4-f490-4293-87aa-1eac69a671d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "#     \"\"\"Takes in some text, removes specific punctuations from them\"\"\"\n",
    "#     punctuation_to_remove = r\"[\\[\\]\\(\\)!?‘’'\\'\\\"\\.,;:]\"\n",
    "#     # punctuation_to_remove = r\"[\\[\\]\\(\\)!?\\\"\\.,;:]\"\n",
    "#     no_punc = re.sub(punctuation_to_remove, \"\", text)\n",
    "#     no_punc_words = [word for word in text if word not in punctuation]\n",
    "#     no_punc = ''.join(no_punc_words)\n",
    "    \n",
    "#     return no_punc\n",
    "    punctuation_to_remove = r\"[\\[\\]\\(\\)!?‘’'\\\".,;:]\"\n",
    "    no_punc = re.sub(punctuation_to_remove, \"\", text)\n",
    "    return no_punc\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def remove_stopwords_from_sentence(sentence):\n",
    "\n",
    "    filtered_words = [word for word in sentence.split() if word.lower() not in stop_words]\n",
    "    \n",
    "    filtered_sentence = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b00d7b64-b19f-40b7-a90b-9be8e292dd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 'reply', 'banking', 'bank', 'app', 'apps', 'banks', 'cibc', 'rbc', 'td', 'scotia', 'bmo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a2afa-df7e-4f5a-a28f-31db166bc87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e10ce-b1f0-447b-b3c1-f489a8139fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158c564-67c8-40a7-9e69-b0a60044fa49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f8f43-918c-45c8-bdbc-a719bcb11ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1a1bfc-03ca-4af9-92e5-b6a6bdac4ea7",
   "metadata": {},
   "source": [
    "## MANUAL DATA LABELING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140094e-2310-47d3-ae66-c20c1db381c0",
   "metadata": {},
   "source": [
    "### IOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ea05d18-a103-449c-ad1d-86965a4c587c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ios_data = pd.read_csv(\"top5banksReviews_v1.csv\")\n",
    "df_copy = ios_data.copy() # keeping a copy of the original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28388ad3-f8d7-46e4-8b1c-d5823cdf07b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------- START OF CHATGPT CODE\n",
    "def is_english(text):\n",
    "    DetectorFactory.seed = 0\n",
    "    \"\"\"input needs to be string\"\"\"\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False  \n",
    "    \n",
    "ios_data['is_english'] = ios_data['review'].apply(is_english)\n",
    "\n",
    "# ---------------------- END OF CHATGPT CODE \n",
    "\n",
    "ios_data = ios_data[ios_data['is_english']].drop(columns=['is_english']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bfcfb5f-db10-477b-a87f-3106813afb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ios_data.to_csv(\"ios_english_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dba2ff6-4727-4659-ba0c-ee87e81fcd04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Could Use Improvements</td>\n",
       "      <td>If there is only one possible account, I shoul...</td>\n",
       "      <td>BMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Verify</td>\n",
       "      <td>Suddenly I am being asked to verify this devic...</td>\n",
       "      <td>BMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Works terrible on my new phone</td>\n",
       "      <td>On my new phone, practically every time I open...</td>\n",
       "      <td>BMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bare bones app</td>\n",
       "      <td>No features to make this app stand out amongst...</td>\n",
       "      <td>BMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not working with iOS12.2</td>\n",
       "      <td>This app won’t work with iOS12.2. Every time I...</td>\n",
       "      <td>BMO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           title  \\\n",
       "0       4          Could Use Improvements   \n",
       "1       4                          Verify   \n",
       "2       1  Works terrible on my new phone   \n",
       "3       1                  Bare bones app   \n",
       "4       1        Not working with iOS12.2   \n",
       "\n",
       "                                              review Bank  \n",
       "0  If there is only one possible account, I shoul...  BMO  \n",
       "1  Suddenly I am being asked to verify this devic...  BMO  \n",
       "2  On my new phone, practically every time I open...  BMO  \n",
       "3  No features to make this app stand out amongst...  BMO  \n",
       "4  This app won’t work with iOS12.2. Every time I...  BMO  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ios_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ea8c51-65b9-46b5-b7b2-68c7b543d8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5542060278902383"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_ios_ratings = np.mean(ios_data['rating'])\n",
    "average_ios_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd8bda7-6842-41a2-a4c4-a592c1ca5e72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.675954978320234"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_ios_ratings = np.std(ios_data['rating'])\n",
    "std_ios_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d321b73-2066-49fe-aec9-e17728452d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upper_accepted = int(average_ios_ratings) + int(std_ios_ratings)\n",
    "lower_accepted = int(average_ios_ratings) - int(std_ios_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27afda07-f70c-4542-95ff-fb61a34b4ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manual_labeling(score):\n",
    "    man_label = ' '\n",
    "    \n",
    "    if score > upper_accepted: \n",
    "        man_label = 'positive'\n",
    "    elif score <= lower_accepted: \n",
    "        man_label = 'negative'\n",
    "    else:\n",
    "        man_label = 'neutral'\n",
    "        \n",
    "    return man_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d1fd7b9-383f-4572-a015-d2d5e6ed7d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ios_data['man_label'] = ios_data['rating'].apply(manual_labeling)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9549a386-780e-49d5-8b52-b288eb507062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>Bank</th>\n",
       "      <th>man_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Could Use Improvements</td>\n",
       "      <td>If there is only one possible account, I shoul...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Verify</td>\n",
       "      <td>Suddenly I am being asked to verify this devic...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Works terrible on my new phone</td>\n",
       "      <td>On my new phone, practically every time I open...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bare bones app</td>\n",
       "      <td>No features to make this app stand out amongst...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not working with iOS12.2</td>\n",
       "      <td>This app won’t work with iOS12.2. Every time I...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           title  \\\n",
       "0       4          Could Use Improvements   \n",
       "1       4                          Verify   \n",
       "2       1  Works terrible on my new phone   \n",
       "3       1                  Bare bones app   \n",
       "4       1        Not working with iOS12.2   \n",
       "\n",
       "                                              review Bank man_label  \n",
       "0  If there is only one possible account, I shoul...  BMO  positive  \n",
       "1  Suddenly I am being asked to verify this devic...  BMO  positive  \n",
       "2  On my new phone, practically every time I open...  BMO  negative  \n",
       "3  No features to make this app stand out amongst...  BMO  negative  \n",
       "4  This app won’t work with iOS12.2. Every time I...  BMO  negative  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ios_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9dc74e9c-87df-46f2-bf48-6d5a09fae545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11115 entries, 0 to 11979\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   rating     11115 non-null  int64 \n",
      " 1   title      11114 non-null  object\n",
      " 2   review     11115 non-null  object\n",
      " 3   Bank       11115 non-null  object\n",
      " 4   man_label  11115 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 521.0+ KB\n"
     ]
    }
   ],
   "source": [
    "ios_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c884edc-2ca5-46cc-8548-7c7a58e2e693",
   "metadata": {},
   "source": [
    "##### TextBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4bc75e94-7ce1-4a8d-82e7-f1c2649b7678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polarity_blob = [TextBlob(review).sentiment.polarity for review in ios_data['review']]\n",
    "# polarity_test = [TextBlob(review).sentiment.polarity for review in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3174d1da-33a8-437d-8f09-728165d9e24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11499999999999999,\n",
       " 0.0,\n",
       " 0.0957070707070707,\n",
       " -0.10833333333333334,\n",
       " 0.0,\n",
       " -0.3,\n",
       " -0.3569444444444445,\n",
       " 0.05416666666666667,\n",
       " -0.046875,\n",
       " -0.4212121212121212]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_blob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf13f7b6-092c-40d8-960f-ccccb6fc1790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjectivity_blob = [TextBlob(review).sentiment.subjectivity for review in ios_data['review']]\n",
    "# subjectivity_test = [TextBlob(review).sentiment.subjectivity for review in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ace5436-ea37-496b-a80a-5c75a37b86f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.595,\n",
       " 0.5,\n",
       " 0.3366161616161616,\n",
       " 0.425,\n",
       " 0.25,\n",
       " 0.5499999999999999,\n",
       " 0.5673611111111111,\n",
       " 0.4,\n",
       " 0.42083333333333334,\n",
       " 0.6848484848484849]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity_blob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8132e190-76c6-484c-8f6a-e6695f1b3dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_polarity_to_label(pol_scores):\n",
    "    \"\"\" \n",
    "    Takes in as input a list of polarity scores, and replaces them with labels of positive, negative or neutral\n",
    "    According to this: \n",
    "        * The value of polarity is between -1 and +1 --- a distance of 2, if I break it into 3 sections \n",
    "        * A value closer to -1 means more negative \n",
    "        * A value closer to +1 means more positive \n",
    "    I have set a harsh threshold of 0.6 (more than 0.5)\n",
    "    Anything less than -1/3 is negative \n",
    "    Anything between -1/3 and 1/3 is neutral\n",
    "    Anything between 1/3 and 1 is positive \n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for score in pol_scores:\n",
    "        if score <= -1*(1/3):\n",
    "            labels.append('negative')\n",
    "        elif score > -1 * (1/3) and score < 1/3: \n",
    "            labels.append('neutral')\n",
    "        else:\n",
    "            labels.append('positive')\n",
    "            \n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "646f787e-5c91-4153-b4b7-b1f3963f8193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob_labels = convert_polarity_to_label(polarity_blob)\n",
    "ios_data['blob_labels'] = pd.Series(blob_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "89dba273-c789-487d-a6bc-6de1ff48333f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>Bank</th>\n",
       "      <th>man_label</th>\n",
       "      <th>blob_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Could Use Improvements</td>\n",
       "      <td>If there is only one possible account, I shoul...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Verify</td>\n",
       "      <td>Suddenly I am being asked to verify this devic...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Works terrible on my new phone</td>\n",
       "      <td>On my new phone, practically every time I open...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bare bones app</td>\n",
       "      <td>No features to make this app stand out amongst...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not working with iOS12.2</td>\n",
       "      <td>This app won’t work with iOS12.2. Every time I...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           title  \\\n",
       "0       4          Could Use Improvements   \n",
       "1       4                          Verify   \n",
       "2       1  Works terrible on my new phone   \n",
       "3       1                  Bare bones app   \n",
       "4       1        Not working with iOS12.2   \n",
       "\n",
       "                                              review Bank man_label  \\\n",
       "0  If there is only one possible account, I shoul...  BMO  positive   \n",
       "1  Suddenly I am being asked to verify this devic...  BMO  positive   \n",
       "2  On my new phone, practically every time I open...  BMO  negative   \n",
       "3  No features to make this app stand out amongst...  BMO  negative   \n",
       "4  This app won’t work with iOS12.2. Every time I...  BMO  negative   \n",
       "\n",
       "  blob_labels  \n",
       "0     neutral  \n",
       "1     neutral  \n",
       "2     neutral  \n",
       "3     neutral  \n",
       "4     neutral  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ios_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ae09243-e76d-45d7-acf0-f4160742c024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob accuracy\n",
      "2637\n",
      "% of success:  0.23724696356275304\n"
     ]
    }
   ],
   "source": [
    "def calculate_success(compare, what):\n",
    "    count_success = 0\n",
    "    compare = list(compare)\n",
    "    what = list(what)\n",
    "\n",
    "    for i in range(len(compare)):\n",
    "        if compare[i] == what[i]:\n",
    "            count_success += 1\n",
    "        else:\n",
    "            count_success = count_success\n",
    "\n",
    "    print(count_success)\n",
    "    print(\"% of success: \", count_success/len(compare))\n",
    "\n",
    "\n",
    "print(\"TextBlob accuracy\")\n",
    "calculate_success(ios_data['man_label'], ios_data['blob_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afa0b2-7ec0-4333-ae63-50a3e23cb24f",
   "metadata": {},
   "source": [
    "##### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bb9f913f-dd5d-4124-9f2c-df0ac6156931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e69bf1ac-83d2-4f16-8c02-a61381a74803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vader_polarity = [sentiment.polarity_scores(review) for review in ios_data['review']]\n",
    "# vader_testing = [sentiment.polarity_scores(review) for review in x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ccb1065-ffb7-42da-99d3-9d670bc7c842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'neg': 0.0, 'neu': 0.941, 'pos': 0.059, 'compound': 0.4404},\n",
       " {'neg': 0.0, 'neu': 0.891, 'pos': 0.109, 'compound': 0.4696},\n",
       " {'neg': 0.026, 'neu': 0.92, 'pos': 0.054, 'compound': 0.6586}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_polarity[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "179e8e31-677b-442a-bc3b-a811f35f64b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_vader_to_label(vader_scores):\n",
    "    \"\"\" \n",
    "    Takes in as input a list of vader dictionary scores.\n",
    "    Each vader dictionary has scores for 'neg', 'neu' and 'pos'.\n",
    "    This function finds the labels based on the compound score; a value between -1 and 1 \n",
    "        * The value of compound is between -1 and +1 --- a distance of 2, if I break it into 3 sections \n",
    "        * A value closer to -1 means more negative \n",
    "        * A value closer to +1 means more positive \n",
    "    Anything less than -1/3 is negative \n",
    "    Anything between -1/3 and 1/3 is neutral\n",
    "    Anything between 1/3 and 1 is positive \n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    for dict_ in vader_scores:\n",
    "        #first, loop through the lists and grab the dictionary - each dictionary is one review \n",
    "        compound = dict_['compound']\n",
    "        \n",
    "        if compound <= -0.05:\n",
    "            labels.append(\"negative\")\n",
    "        elif compound >= 0.05:\n",
    "            labels.append(\"positive\")\n",
    "        else:\n",
    "            labels.append(\"neutral\")\n",
    "    \n",
    "    #another way to do it: \n",
    "#     for dict_ in vader_scores:\n",
    "#         #---------------------------- START CHATGPT CODE \n",
    "#         dict_without_compound = {k: v for k, v in dict_.items() if k != \"compound\"}\n",
    "#         max_key = max(dict_without_compound, key = dict_without_compound.get)\n",
    "#         labels.append(max_key)\n",
    "#         #---------------------------- END CHATGPT CODE \n",
    "                \n",
    "#     for i in range(len(labels)):\n",
    "#         if labels[i] == 'neg':\n",
    "#             labels[i] = 'negative'\n",
    "#         elif labels[i] == 'pos':\n",
    "#             labels[i] = 'positive'\n",
    "#         else:\n",
    "#             labels[i] = 'neutral'\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6f902de-7b43-4a1e-9739-d4e397abb618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vader_labels = convert_vader_to_label(vader_polarity)\n",
    "ios_data['vader_labels'] = pd.Series(vader_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d9b5872d-f17a-4f01-92d3-2b9c9f20b1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader accuracy\n",
      "3696\n",
      "% of success:  0.33252361673414305\n"
     ]
    }
   ],
   "source": [
    "print(\"Vader accuracy\")\n",
    "calculate_success(ios_data['man_label'], ios_data['vader_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d8bbb30-4c61-4e31-ba83-f4ba9d274967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>Bank</th>\n",
       "      <th>man_label</th>\n",
       "      <th>blob_labels</th>\n",
       "      <th>vader_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Could Use Improvements</td>\n",
       "      <td>If there is only one possible account, I shoul...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Verify</td>\n",
       "      <td>Suddenly I am being asked to verify this devic...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Works terrible on my new phone</td>\n",
       "      <td>On my new phone, practically every time I open...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bare bones app</td>\n",
       "      <td>No features to make this app stand out amongst...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not working with iOS12.2</td>\n",
       "      <td>This app won’t work with iOS12.2. Every time I...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           title  \\\n",
       "0       4          Could Use Improvements   \n",
       "1       4                          Verify   \n",
       "2       1  Works terrible on my new phone   \n",
       "3       1                  Bare bones app   \n",
       "4       1        Not working with iOS12.2   \n",
       "\n",
       "                                              review Bank man_label  \\\n",
       "0  If there is only one possible account, I shoul...  BMO  positive   \n",
       "1  Suddenly I am being asked to verify this devic...  BMO  positive   \n",
       "2  On my new phone, practically every time I open...  BMO  negative   \n",
       "3  No features to make this app stand out amongst...  BMO  negative   \n",
       "4  This app won’t work with iOS12.2. Every time I...  BMO  negative   \n",
       "\n",
       "  blob_labels vader_labels  \n",
       "0     neutral     positive  \n",
       "1     neutral     positive  \n",
       "2     neutral     positive  \n",
       "3     neutral     negative  \n",
       "4     neutral     negative  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ios_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a35b9-b367-4922-823c-a376185897c7",
   "metadata": {},
   "source": [
    "##### MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "52d58a98-bf4e-407d-98af-ae4a64311902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews = list(ios_data['review']) \n",
    "reviews_corpus = \" \".join([str(review) for review in reviews])\n",
    "tokenized_doc_to_sentences = sent_tokenize(reviews_corpus)\n",
    "tokenized_doc_to_words = [word_tokenize(sent) for sent in tokenized_doc_to_sentences]\n",
    "\n",
    "reviews_corpus_lc = list(ios_data['review'])\n",
    "reviews_corpus_lc = [review.lower() for review in reviews_corpus_lc]\n",
    "\n",
    "tokenized_doc_to_sentences_lc = sent_tokenize(' '.join(reviews_corpus_lc))\n",
    "tokenized_doc_to_words_lc = [word_tokenize(sent) for sent in tokenized_doc_to_sentences_lc]\n",
    "\n",
    "reviews_corpus_stpw = list(ios_data['review'].apply(remove_stopwords_from_sentence))\n",
    "tokenized_doc_to_sentences_stpw = sent_tokenize(' '.join(reviews_corpus_stpw))\n",
    "tokenized_doc_to_words_stpw = [word_tokenize(sent) for sent in tokenized_doc_to_sentences_stpw]\n",
    "\n",
    "\n",
    "reviews_corpus_noPnc = [remove_punc(review) for review in reviews_corpus_stpw] \n",
    "tokenized_doc_to_sentences_noPnc = [remove_punc(sentence) for sentence in tokenized_doc_to_sentences_stpw]\n",
    "tokenized_doc_to_words_noPnc = [word_tokenize(sent) for sent in tokenized_doc_to_sentences_noPnc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aed6de35-9a62-4ff4-925b-f2cfadc8a52c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yekta/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# SOURCE for code: https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+') # get rid of punctuation and non alphanumeric characters + tokenize to word \n",
    "\n",
    "cv = CountVectorizer(stop_words = 'english', ngram_range = (1,1), tokenizer = token.tokenize) #count word matrix \n",
    "\n",
    "reviews_word_counts = cv.fit_transform(ios_data['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6e9ba07f-53c9-4aa7-be21-737f1ebe0128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(reviews_word_counts, ios_data['man_label'], test_size = 0.2, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a020905-e84a-4f9b-bd84-41b58626ec9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB = MultinomialNB()\n",
    "multinomialNB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ce42baa3-f77f-4a47-bb02-7b43fca26782",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB Accuracy  0.6675663517768781\n"
     ]
    }
   ],
   "source": [
    "multinomialNB_predicted = multinomialNB.predict(x_test)\n",
    "accuracy_multinomialNB = metrics.accuracy_score(multinomialNB_predicted, y_test)\n",
    "\n",
    "print(\"Multinomial NB Accuracy \", accuracy_multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3595cc6e-390e-4aec-9723-a1aa922c56b9",
   "metadata": {},
   "source": [
    "##### LSTM\n",
    "\n",
    "Source for code was originally [AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/), but the code used several [depricated](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) modules/packages/functions from packages. As well, keras is now integrated into tensorflow. So, I used ChatGPT's help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d684fad6-9964-408c-9ae9-3da4ae9ab170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleaning(df, stop_words):\n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    \n",
    "    df['review'] = df['review'].apply(lambda x: re.sub(r'\\d+', '', x))  # regex for digits\n",
    "    \n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join(x for x in x.split() if x not in stop_words))\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cf07903f-7fa9-4528-a7be-20a86a7a4edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ios_cleaned = cleaning(ios_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "83fa2038-31d7-4d04-8602-5829e1ed1b60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>Bank</th>\n",
       "      <th>man_label</th>\n",
       "      <th>blob_labels</th>\n",
       "      <th>vader_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Could Use Improvements</td>\n",
       "      <td>one possible account, select time need deposit...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Verify</td>\n",
       "      <td>suddenly asked verify device almost every time...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Works terrible on my new phone</td>\n",
       "      <td>new phone, practically every time open asks ve...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Bare bones app</td>\n",
       "      <td>feature make stand amongst canadian banks. poo...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Not working with iOS12.2</td>\n",
       "      <td>won’t work ios.. every time open turn white st...</td>\n",
       "      <td>BMO</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                           title  \\\n",
       "0       4          Could Use Improvements   \n",
       "1       4                          Verify   \n",
       "2       1  Works terrible on my new phone   \n",
       "3       1                  Bare bones app   \n",
       "4       1        Not working with iOS12.2   \n",
       "\n",
       "                                              review Bank man_label  \\\n",
       "0  one possible account, select time need deposit...  BMO  positive   \n",
       "1  suddenly asked verify device almost every time...  BMO  positive   \n",
       "2  new phone, practically every time open asks ve...  BMO  negative   \n",
       "3  feature make stand amongst canadian banks. poo...  BMO  negative   \n",
       "4  won’t work ios.. every time open turn white st...  BMO  negative   \n",
       "\n",
       "  blob_labels vader_labels  \n",
       "0     neutral     positive  \n",
       "1     neutral     positive  \n",
       "2     neutral     positive  \n",
       "3     neutral     negative  \n",
       "4     neutral     negative  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ios_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1ecca1be-7f9e-4722-a692-7c090dc8db7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 500, split = ' ')\n",
    "tokenizer.fit_on_texts(ios_cleaned['review'].values)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(ios_cleaned['review'].values)\n",
    "X = pad_sequences(X)\n",
    "\n",
    "y = pd.get_dummies(ios_cleaned['man_label']).values  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d19bd34d-bfd5-4e28-8d02-a44f9b5c372d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# Model Building\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=500, output_dim=120, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(352))  \n",
    "model.add(LeakyReLU(alpha=0.3))   \n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3c53f6b6-c52e-4b74-bd22-d6b0e6577d60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 731ms/step - accuracy: 0.5607 - loss: 0.9549\n",
      "Epoch 2/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 744ms/step - accuracy: 0.6682 - loss: 0.7641\n",
      "Epoch 3/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 789ms/step - accuracy: 0.6936 - loss: 0.7198\n",
      "Epoch 4/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 829ms/step - accuracy: 0.7086 - loss: 0.6810\n",
      "Epoch 5/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 809ms/step - accuracy: 0.7081 - loss: 0.6719\n",
      "Epoch 6/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 833ms/step - accuracy: 0.7135 - loss: 0.6458\n",
      "Epoch 7/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 807ms/step - accuracy: 0.7264 - loss: 0.6279\n",
      "Epoch 8/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 870ms/step - accuracy: 0.7387 - loss: 0.6205\n",
      "Epoch 9/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 902ms/step - accuracy: 0.7370 - loss: 0.6044\n",
      "Epoch 10/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 861ms/step - accuracy: 0.7352 - loss: 0.6026\n",
      "Epoch 11/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 853ms/step - accuracy: 0.7544 - loss: 0.5723\n",
      "Epoch 12/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 830ms/step - accuracy: 0.7592 - loss: 0.5677\n",
      "Epoch 13/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 895ms/step - accuracy: 0.7499 - loss: 0.5496\n",
      "Epoch 14/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 847ms/step - accuracy: 0.7669 - loss: 0.5413\n",
      "Epoch 15/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 859ms/step - accuracy: 0.7753 - loss: 0.5210\n",
      "Epoch 16/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 961ms/step - accuracy: 0.7820 - loss: 0.5138\n",
      "Epoch 17/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 830ms/step - accuracy: 0.7861 - loss: 0.4904\n",
      "Epoch 18/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 802ms/step - accuracy: 0.7961 - loss: 0.4610\n",
      "Epoch 19/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 853ms/step - accuracy: 0.8134 - loss: 0.4504\n",
      "Epoch 20/20\n",
      "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 853ms/step - accuracy: 0.8212 - loss: 0.4291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe2829d9c90>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "192886cf-d942-40bf-a8d1-bcdaf0bf2986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - accuracy: 0.6127 - loss: 1.0943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1226282119750977, 0.6320288181304932]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158e85e-a526-44ae-900f-3c3eb17433e6",
   "metadata": {},
   "source": [
    "###### A LITTLE BACK AND FORTH WITH CHATGPT \n",
    "1. `input_dim = 500`:<br>\n",
    "    This represents the size of the vocabulary or the number of unique tokens (words) that the Embedding layer will handle.\n",
    "    In your code, the tokenizer is set to consider the 500 most frequent words (`num_words=500`). \n",
    "    This means you want to limit the vocabulary to the top 500 most frequent words found in your dataset.\n",
    "    The `input_dim` should match this value.\n",
    "    \n",
    "    > Why 500? <br>\n",
    "    \n",
    "    This is a commonly used number to control the size of the vocabulary. \n",
    "    It's a trade-off between having enough words to cover important vocabulary and not making the model too large or slow by using an excessively large vocabulary. \n",
    "    You can adjust this value based on the size of your dataset and the problem you're working on.\n",
    "\n",
    "    > `tokenizer = Tokenizer(num_words=500, split=' ')`\n",
    "\n",
    "    `input_dim` should be set to `num_words + 1`, but we typically set `input_dim` to 500 if we are using the top 500 words.\n",
    "    If you increase the value of `num_words`, you can make your model handle a larger vocabulary (**but keep in mind that this increases memory usage and computational time**).\n",
    "\n",
    "2. `output_dim = 120`:<br>\n",
    "    This refers to the dimensionality of the word embeddings.\n",
    "    Word embeddings are continuous vector representations of words, and `output_dim` specifies the size of each word’s embedding vector.\n",
    "   \n",
    "    > Why 120?: <br>\n",
    "        \n",
    "    The value of `output_dim` is usually chosen based on empirical results or experimentation. \n",
    "    Typical values range from 50 to 300.\n",
    "    Larger values (like 120, 300) usually capture more semantic information about words but require more computational resources.\n",
    "    Setting `output_dim = 120` is a common choice, as it strikes a balance between capturing enough semantic information and managing memory usage. \n",
    "    However, this is a hyperparameter that you can tune based on your dataset and model performance.\n",
    "    If you use pre-trained word embeddings (like GloVe, Word2Vec), `output_dim` is typically determined by the size of the pre-trained embeddings.\n",
    "    If you are learning embeddings from scratch, you can experiment with different sizes.\n",
    "\n",
    "3. Example of embedding setup:\n",
    "\n",
    "`model.add(Embedding(input_dim=500, output_dim=120, input_length=X.shape[1]))`\n",
    "\n",
    "    `input_dim=500`: You’re working with a vocabulary of the top 500 words, so the model will have embeddings for each of those 500 words.\\\\\n",
    "    `output_dim=120`: Each word will be represented by a 120-dimensional vector in the embedding space.\n",
    "\n",
    "**When to adjust these values:**\n",
    "\n",
    "    `input_dim`: If you want your model to understand more than the top 500 words, you can increase this number. \n",
    "    However, increasing it might also make the model slower and more memory-intensive.\n",
    "\n",
    "    `output_dim`: You can experiment with this value (e.g., 50, 100, 200) depending on how much information you want each word's embedding to capture. Larger values may improve the model’s ability to understand word relationships but at the cost of more computation.\n",
    "\n",
    "***\n",
    "\n",
    "While the epochs are running, I (Yekta) read the code in more detail and learned a few things. I'll write them down: \n",
    "\n",
    "1. `Sequential()` generates a model which is built layer by layer (in \"sequence\")\n",
    "2. `.add(Embedding)` is the embedding layer, which basically replaced the Word2Vec or other word embeddings - which is basically the semantic representation of words (to find similar words). In here, the `input_length` is the length of the X value, which is the number of words per review\n",
    "3. `SpatialDropout1D` is a regularization technique that drops 40% of the features (words here) to not overfit \n",
    "4. `LSTM` is obvious Long Short-Term Memory with 704 neurons. Why 704? Probably similar to above rational, drops 20% of the words to not overfit, and not sure about LSTM's internal memory but the `recurrent_dropout` is to avoid overfitting there\n",
    "5. `Dense(352)` is the first fully connected layer with 352 neurons, and it uses a `LeakyReLU` activation function (which I had to add as a separate layer)\n",
    "6. `Dense(3)` is the last layer, which gives me probabilities for positive, negative and neutral labels and uses `softmax`\n",
    "7. `compile` determines the loss function (`categorical_crossentropy`: because it's multiclass classification), `optimizer`: adam, to tune the weights during learning to minimize loss, and `accuracy` for the performance measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e750a6-2f38-48e6-bc20-5dd68f968fc8",
   "metadata": {},
   "source": [
    "##### WHAT IF I WANTED TO USE WORD2VEC or BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe191ad-4ac2-4657-9cec-d4a0b2b46271",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------- START OF CHATGPT CODE \n",
    "# Step 1: Load pre-trained Word2Vec model (Google's pre-trained model is large)\n",
    "# w2v_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# # Step 2: Create an embedding matrix (size: vocabulary size x embedding dimension)\n",
    "# embedding_dim = 300  # Typically, Word2Vec uses 300-dimensional vectors\n",
    "# embedding_matrix = np.zeros((500, embedding_dim))  # Initialize a matrix for top 500 words\n",
    "\n",
    "# # Map each word in the vocabulary to its Word2Vec vector (if available)\n",
    "# for word, i in tokenizer.word_index.items():\n",
    "#     if i < 500:  # We are using the top 500 words\n",
    "#         if word in w2v_model:\n",
    "#             embedding_matrix[i] = w2v_model[word]\n",
    "\n",
    "# # Step 3: Replace the embedding layer with the pre-trained Word2Vec embeddings\n",
    "# model_word2Vec = Sequential()\n",
    "# model_word2Vec.add(Embedding(input_dim=500, output_dim=embedding_dim, input_length=X.shape[1], \n",
    "#                     weights=[embedding_matrix], trainable=False))  # Freezing the embeddings\n",
    "# model_word2Vec.add(SpatialDropout1D(0.4))\n",
    "# model_word2Vec.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model_word2Vec.add(Dense(352, activation=LeakyReLU(alpha=0.3)))\n",
    "# model_word2Vec.add(Dense(3, activation='softmax'))\n",
    "# model_word2Vec.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# -------------------------- END OF CHATGPT CODE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77118f57-45ee-4a31-b44e-fb060186fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2Vec.fit(x_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0101e-4bb2-4bd8-944b-ead012354dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2Vec.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb7d81-7659-43f3-b021-b8d589b33212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c8dd6-b2c8-4cbb-97f3-25b35ff4d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------- START OF CHATGPT CODE \n",
    "\n",
    "# # Step 1: Load BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Step 2: Tokenize the sentences and pad sequences\n",
    "# inputs = tokenizer(ios_cleaned['review'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# # Step 3: Use BERT embeddings for input\n",
    "# model_BERT = Sequential()\n",
    "# model_BERT.add(tf.keras.layers.InputLayer(input_shape=(inputs['input_ids'].shape[1],)))  # Input layer size should match tokenized input length\n",
    "# model_BERT.add(bert_model)  # Apply the BERT model to get embeddings\n",
    "# model_BERT.add(SpatialDropout1D(0.4))\n",
    "# model_BERT.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model_BERT.add(Dense(352, activation=LeakyReLU(alpha=0.3)))\n",
    "# model_BERT.add(Dense(3, activation='softmax'))\n",
    "# model_BERT.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# -------------------------- END OF CHATGPT CODE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae1085-4aa1-41a0-ad38-caf2c04c3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_BERT.fit(x_train, y_train, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878f8a9-01d5-4848-9990-07db190e2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_BERT.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475224b-b898-4ba6-a2e5-b9fd93735606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e51d812c-22b3-4434-a3f4-2fc2b67a226e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 186ms/step\n"
     ]
    }
   ],
   "source": [
    "# label using the model \n",
    "X_ = tokenizer.texts_to_sequences(ios_cleaned['review'].values)\n",
    "X_ = pad_sequences(X_, maxlen = X.shape[1])\n",
    "\n",
    "predictions_model = model.predict(X_)\n",
    "\n",
    "label_map = {0: 'negative',\n",
    "             1: 'neutral',\n",
    "             2: 'positive'}\n",
    "\n",
    "predicted_labels_model = [label_map[np.argmax(pred)] for pred in predictions_model]\n",
    "\n",
    "ios_cleaned['LSTM_label'] = pd.Series(predicted_labels_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "51bc4d14-6399-44dc-abe5-37e3b1b4f713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into 3 \n",
    "negative_data_ios = ios_cleaned[ios_cleaned['LSTM_label'] == \"negative\"]\n",
    "neutral_data_ios = ios_cleaned[ios_cleaned['LSTM_label'] == \"neutral\"]\n",
    "positive_data_ios = ios_cleaned[ios_cleaned['LSTM_label'] == \"positive\"]\n",
    "\n",
    "negative_data_ios.to_csv(\"negative_data_ios.csv\", index=False)\n",
    "neutral_data_ios.to_csv(\"neutral_data_ios.csv\", index=False)\n",
    "positive_data_ios.to_csv(\"positive_data_ios.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b39f9c-cd3d-44fa-8463-b3df6198a09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44796c0d-d262-4d9b-80b8-130626aacf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfda783-11c5-4911-b87d-f8464dc444c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada82895-bf00-4d03-b709-6976d6b958bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
